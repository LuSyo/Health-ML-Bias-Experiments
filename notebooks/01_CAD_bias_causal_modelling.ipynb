{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "V5mc425DXGM4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import userdata\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  PROJECT_ROOT = userdata.get('PROJECT_ROOT')\n",
        "else:\n",
        "  PROJECT_ROOT = '../'\n",
        "\n",
        "!pip install -q tableone\n",
        "!pip install -q tqdm\n",
        "!pip install -q scipy\n",
        "!pip install -q sklearn\n",
        "!pip install -q seaborn\n",
        "!pip install -q matplotlib\n",
        "!pip install -q semopy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zBum-SnZwHC"
      },
      "source": [
        "# Detecting and mitigating bias using causal modelling\n",
        "\n",
        "## The method\n",
        "\n",
        "Introduced by Hui and Lau (2024, doi:[10.1109/CCCIS63483.2024.00016](https://doi.org/10.1109/CCCIS63483.2024.00016)).\n",
        "\n",
        "**Aim:** Detect and mitigate bias on a sensitive attribute in a black-box predictive model, by modelling and infering the causal relationship between the attribute, the model's preedicted outcome and the ground-truth outcome.\n",
        "\n",
        "## The experiment\n",
        "\n",
        "Using the characterisation of statistical gender bias in cardiology algorithms conducted by Straw et al. (2024, doi: [10.2196/46936](https://doi.org/10.2196/46936)) as a reference, we will apply the causal modelling bias mitigation method to the ML model replicated by Straw et al. on the [Heart Disease (CAD) dataset](https://ieee-dataport.org/open-access/heart-disease-dataset-comprehensive).\n",
        "\n",
        "### Hypothesis\n",
        "\n",
        "Causal modelling (as per Hui and Lau's method) will detect a statistically significant direct causal path from the protected attribute (sex) to the prediction outcome, and mitigating this direct path will reduce the observed sex-based performance disparity (FNR difference) in the cardiac disease prediction model.\n",
        "\n",
        "### Key variables\n",
        "\n",
        "- **Protected attribute ($a$):** sex (male/female)\n",
        "- **Actual outcome ($y$):** Heart disease diagnosis / No heart disease diagnosis\n",
        "- **Predicted outcome ($\\hat{y}$):** The continuous probability estimate from the black-box predictive model. The inary class (heart disease / no heart disease) is derived via a threshold.\n",
        "- **Mitigated outcome ($\\tilde{y}$):** the continuous, bias-corrected probability estimate derived from the causal modelling mitigation on the predicted outcome.\n",
        "- **Fairness metrics:**\n",
        "  - Disparity of Predictive Accuracy between subgroups\n",
        "  - Disparity of False Positive Rate (FPR) between subgroups\n",
        "  - Disparity of False Negative Rate (FNR) between subgroups\n",
        "  - Equal Opportunity (EO), satisfied when the FNR disparity between subgroups nears zero\n",
        "\n",
        "$$\\text{FPR} = \\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}}$$\n",
        "\n",
        "$$\\text{FNR} = \\frac{\\text{False Negatives}}{\\text{False Negatives} + \\text{True Positives}}$$\n",
        "\n",
        "$$ EO \\Leftrightarrow FNR_{male} = FNR_{female}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK_djqWEjApw"
      },
      "source": [
        "# Function library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gOBJFpQi2GR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,\\\n",
        " recall_score, roc_auc_score\n",
        "import semopy\n",
        "from scipy.stats import sem, t\n",
        "\n",
        "def train_random_forest(X_train, y_train, X_test, y_test):\n",
        "  '''\n",
        "    Trains a sklearn RandomForestClassifier on the given training data,\\\n",
        "     optimised hyperparameters with 3-fold GridSearchCV\n",
        "\n",
        "     Inputs:\n",
        "       X_train: training features\n",
        "       y_train: training labels\n",
        "       X_test: test features\n",
        "       y_test: test labels\n",
        "\n",
        "     Outputs:\n",
        "       rf: trained RandomForestClassifier\n",
        "       y_pred: predicted labels\n",
        "       y_pred_proba: predicted probabilities\n",
        "  '''\n",
        "  param_grid = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [5, 10, 20, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"min_samples_split\": [2, 5]\n",
        "  }\n",
        "\n",
        "  #create the RF classifier\n",
        "  rf = RandomForestClassifier()\n",
        "\n",
        "  #create the grid search\n",
        "  rf_grid = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='roc_auc', cv=3)\n",
        "\n",
        "  #fit the grid search\n",
        "  rf_grid.fit(X_train, y_train)\n",
        "  y_pred = rf_grid.predict(X_test)\n",
        "  y_pred_proba = rf_grid.predict_proba(X_test)[:,1]\n",
        "\n",
        "  return [rf_grid, y_pred, y_pred_proba]\n",
        "\n",
        "def get_causal_model_params(X_train, y_train, y_pred_proba, protected_attribute):\n",
        "  '''\n",
        "    Trains a semopy causal model on the given training data and predictions,\\\n",
        "     for the following linear causal model:\\\n",
        "      y_pred ~ beta0 + beta1*y_true + beta2*protected_attribute,\\\n",
        "     to identify the causal relationship between the protected attribute\\\n",
        "      and the predicted outcome.\n",
        "\n",
        "     Inputs\n",
        "       X_train: training features\n",
        "       y_train: training labels\n",
        "       y_pred_proba: predicted probabilities\n",
        "       protected_attribute: name of the protected attribute\n",
        "\n",
        "     Outputs\n",
        "       beta2: coefficient of the causal relationship between\\\n",
        "        the protected attribute and the predicted outcome\n",
        "       beta2_pvalue: p-value of the causal relationship\n",
        "  '''\n",
        "  causal_features = pd.DataFrame()\n",
        "  causal_features['protected_attribute'] = X_train[protected_attribute]\n",
        "  causal_features['y_true'] = y_train\n",
        "  causal_features['y_pred'] = y_pred_proba\n",
        "\n",
        "  model_desc='''\n",
        "    y_true ~ protected_attribute\n",
        "    y_pred ~ y_true + protected_attribute\n",
        "  '''\n",
        "\n",
        "  causal_model = semopy.Model(model_desc)\n",
        "  causal_model.fit(causal_features)\n",
        "  causal_params = causal_model.inspect()\n",
        "\n",
        "  # Retrieve the coefficients of the causal model\n",
        "  beta2 = causal_params.loc[(causal_params.rval == \"protected_attribute\") &\n",
        "                            (causal_params.lval == \"y_pred\"),'Estimate'].values[0]\n",
        "  beta2_pvalue = causal_params.loc[(causal_params.rval == \"protected_attribute\") &\n",
        "                            (causal_params.lval == \"y_pred\"),'p-value'].values[0]\n",
        "\n",
        "  return [beta2, beta2_pvalue]\n",
        "\n",
        "def get_perf_metrics(y_true, y_pred, y_pred_proba):\n",
        "  '''\n",
        "    Calculates the performance metrics for a given set of predictions.\n",
        "\n",
        "    Inputs\n",
        "      y_true: true labels\n",
        "      y_pred: predicted labels\n",
        "      y_pred_proba: predicted probabilities\n",
        "\n",
        "    Outputs\n",
        "      accuracy: accuracy score\n",
        "      roc_auc: ROC AUC (Receiver Operating Characteristic Area Under the Curve)\n",
        "      FNR: False Negative Rate\n",
        "      FPR: False Positive Rate\n",
        "      tn: True Negatives\n",
        "      fp: False Positives\n",
        "      fn: False Negatives\n",
        "      tp: True Positives\n",
        "  '''\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  FNR = fn / (fn + tp)\n",
        "  FPR = fp / (fp + tn)\n",
        "\n",
        "  return [accuracy, roc_auc, FNR, FPR, tn, fp, fn, tp]\n",
        "\n",
        "def get_95_ci(data):\n",
        "  '''\n",
        "    Calculates the 95% confidence interval for a given set of data.\n",
        "\n",
        "    Inputs\n",
        "      data: data as a Pandas Series\n",
        "\n",
        "    Outputs\n",
        "      interval: Array of the lower and upper bounds of the confidence interval\n",
        "  '''\n",
        "  n = len(data)\n",
        "  mean = data.mean()\n",
        "  std_err = sem(data)\n",
        "  interval = t.interval(0.95, n - 1, loc=mean, scale=std_err)\n",
        "  return interval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DatSRofcxL3q"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRaoW8zLi2MR",
        "outputId": "ee381dcb-268e-405b-9b13-7190313d05b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             Grouped by sex                                          \n",
            "                                    Missing       Overall             0             1\n",
            "n                                                     746           182           564\n",
            "age, mean (SD)                            0    52.9 (9.5)    52.2 (9.3)    53.1 (9.6)\n",
            "chest pain type, n (%)     1                     41 (5.5)       9 (4.9)      32 (5.7)\n",
            "                           2                   166 (22.3)     59 (32.4)    107 (19.0)\n",
            "                           3                   169 (22.7)     52 (28.6)    117 (20.7)\n",
            "                           4                   370 (49.6)     62 (34.1)    308 (54.6)\n",
            "resting bp s, mean (SD)                   0  133.0 (17.3)  132.0 (18.6)  133.4 (16.8)\n",
            "cholesterol, mean (SD)                    0  244.6 (59.2)  255.8 (62.9)  241.0 (57.5)\n",
            "fasting blood sugar, n (%) 0                   621 (83.2)    163 (89.6)    458 (81.2)\n",
            "                           1                   125 (16.8)     19 (10.4)    106 (18.8)\n",
            "resting ecg, n (%)         0                   445 (59.7)    109 (59.9)    336 (59.6)\n",
            "                           1                   125 (16.8)     26 (14.3)     99 (17.6)\n",
            "                           2                   176 (23.6)     47 (25.8)    129 (22.9)\n",
            "max heart rate, mean (SD)                 0  140.2 (24.5)  147.0 (22.0)  138.0 (24.9)\n",
            "exercise angina, n (%)     0                   459 (61.5)    142 (78.0)    317 (56.2)\n",
            "                           1                   287 (38.5)     40 (22.0)    247 (43.8)\n",
            "oldpeak, mean (SD)                        0     0.9 (1.1)     0.7 (1.0)     1.0 (1.1)\n",
            "ST slope, n (%)            0                      1 (0.1)       0 (0.0)       1 (0.2)\n",
            "                           1                   349 (46.8)    107 (58.8)    242 (42.9)\n",
            "                           2                   353 (47.3)     70 (38.5)    283 (50.2)\n",
            "                           3                     43 (5.8)       5 (2.7)      38 (6.7)\n",
            "target, n (%)              0                   390 (52.3)    142 (78.0)    248 (44.0)\n",
            "                           1                   356 (47.7)     40 (22.0)    316 (56.0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tableone import TableOne\n",
        "\n",
        "heart_disease = pd.read_csv(f'{PROJECT_ROOT}data/heart_disease_cleveland_hungary.csv')\n",
        "\n",
        "# Remove duplicates and null values, as per Straw et al.\n",
        "\n",
        "rows_to_drop  = (heart_disease['cholesterol'] == 0) | (heart_disease['resting bp s'] == 0) | (heart_disease.duplicated(keep='first'))\n",
        "heart_disease.drop(heart_disease[rows_to_drop].index, inplace=True)\n",
        "\n",
        "if (len(heart_disease) != 746): print(\"WARNING: Total count of records in cleaned dataset doesn't match reference study\" )\n",
        "\n",
        "# Descriptive statistics\n",
        "table1 = TableOne(heart_disease,\n",
        "                  groupby='sex',\n",
        "                  continuous=['age','cholesterol','max heart rate','resting bp s','oldpeak'],\n",
        "                  categorical=['target','chest pain type', 'fasting blood sugar','resting ecg','exercise angina','ST slope']\n",
        "                  )\n",
        "\n",
        "print(table1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxhZ5W2uxSFx"
      },
      "outputs": [],
      "source": [
        "# Features and target outcomes\n",
        "X = heart_disease.drop(['target'], axis=1)\n",
        "y = heart_disease['target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfSxBTpox8RB"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQdHCnbix7rG",
        "outputId": "6d7ec520-e155-4c2f-8779-9e6804986d25"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running simulations: 100%|██████████| 100/100 [54:10<00:00, 32.50s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from scipy.stats import barnard_exact\n",
        "import numpy as np\n",
        "\n",
        "# Bootstrapping approach with N_RUNS runs and a 70/30 training/test split\n",
        "N_RUNS = 100\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=N_RUNS, test_size=0.3, random_state=4)\n",
        "\n",
        "perf_metrics = []\n",
        "\n",
        "for i, (train_index, test_index) in tqdm(enumerate(sss.split(X, y)), total=N_RUNS, desc=\"Running simulations\"):\n",
        "\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  rf, y_pred, y_pred_proba = train_random_forest(X_train, y_train, X_test, y_test)\n",
        "\n",
        "  #measure global performance metrics\n",
        "  accuracy, roc_auc, FNR, FPR,*_ = get_perf_metrics(y_test, y_pred, y_pred_proba)\n",
        "\n",
        "  # Causal Model Analysis on the training set\n",
        "  # Considering the following causal model:\n",
        "  # y_pred = beta0 + beta1*y_true + beta2*a\n",
        "  # where a is the protected attribute, i.e. sex\n",
        "  y_train_pred_proba = rf.predict_proba(X_train)[:, 1]\n",
        "  beta2, beta2_pvalue = get_causal_model_params(X_train, y_train, y_train_pred_proba, 'sex')\n",
        "\n",
        "  # Audit dataset\n",
        "  audit_df = X_test.copy()\n",
        "  audit_df['y_true'] = y_test\n",
        "  audit_df['y_pred'] = y_pred\n",
        "  audit_df['y_pred_proba'] = y_pred_proba\n",
        "\n",
        "\n",
        "  # CAUSAL MITIGATION\n",
        "  if (beta2_pvalue < 0.05):\n",
        "    # Calculate y_correct_proba from y_pred_proba\n",
        "    # and y_train_pred_correct_proba from y_train_pred_proba\n",
        "    audit_df['y_correct_proba'] = audit_df['y_pred_proba'] - beta2*audit_df['sex']\n",
        "    y_train_pred_correct_proba = y_train_pred_proba - beta2*X_train['sex']\n",
        "\n",
        "    # Apply classification threshold as per Hui and Lau,\n",
        "    # using the quantile in y_correct matching the prevalence of the negative class in the training set:\n",
        "    target_prevalence = y_train.value_counts()[0] / len(y_train)\n",
        "    # print(f'Prevalence: {target_prevalence}')\n",
        "    threshold = y_train_pred_correct_proba.quantile(target_prevalence)\n",
        "    audit_df['y_correct'] = (audit_df['y_correct_proba'] > threshold).astype(int)\n",
        "\n",
        "  else:\n",
        "    audit_df['y_correct_proba'] = audit_df['y_pred_proba']\n",
        "    audit_df['y_correct'] = audit_df['y_pred']\n",
        "\n",
        "\n",
        "  # Global perf of the corrected model\n",
        "  accuracy_corrected, roc_auc_corrected, FNR_corrected, FPR_corrected, *_ = get_perf_metrics(\n",
        "      audit_df['y_true'],\n",
        "      audit_df['y_correct'],\n",
        "      audit_df['y_correct_proba']\n",
        "  )\n",
        "\n",
        "  # STRATIFIED PERFORMANCE AUDIT\n",
        "  male_df = audit_df[audit_df['sex'] == 1]\n",
        "  female_df = audit_df[audit_df['sex'] == 0]\n",
        "\n",
        "  ## Baseline model\n",
        "  accuracy_m, roc_auc_m, FNR_m, FPR_m, tn_m, fp_m, fn_m, tp_m = get_perf_metrics(\n",
        "      male_df['y_true'],\n",
        "      male_df['y_pred'],\n",
        "      male_df['y_pred_proba'])\n",
        "\n",
        "  accuracy_f, roc_auc_f, FNR_f, FPR_f, tn_f, fp_f, fn_f, tp_f = get_perf_metrics(\n",
        "      female_df['y_true'],\n",
        "      female_df['y_pred'],\n",
        "      female_df['y_pred_proba'])\n",
        "\n",
        "  ## Chi-squared test for independence between rate of false negative rate (or true positive rate) and sex\n",
        "  fnr_barnard = barnard_exact([[fn_m, tp_m],[fn_f, tp_f]])\n",
        "  fpr_barnard = barnard_exact([[fp_m, tn_m],[fp_f, tn_f]])\n",
        "\n",
        "  ## Corrected predictions\n",
        "  accuracy_corrected_m, roc_auc_corrected_m, FNR_corrected_m, FPR_corrected_m, *_ = get_perf_metrics(\n",
        "      male_df['y_true'],\n",
        "      male_df['y_correct'],\n",
        "      male_df['y_correct_proba']\n",
        "  )\n",
        "\n",
        "  accuracy_corrected_f, roc_auc_corrected_f, FNR_corrected_f, FPR_corrected_f, *_ = get_perf_metrics(\n",
        "      female_df['y_true'],\n",
        "      female_df['y_correct'],\n",
        "      female_df['y_correct_proba']\n",
        "  )\n",
        "\n",
        "  perf_metrics.append({\n",
        "      'run': i,\n",
        "      'accuracy': accuracy,\n",
        "      'roc_auc': roc_auc,\n",
        "      'FNR': FNR,\n",
        "      'FPR': FPR,\n",
        "      'accuracy_diff': accuracy_m - accuracy_f,\n",
        "      'roc_auc_diff': roc_auc_m - roc_auc_f,\n",
        "      'FNR_diff': FNR_m - FNR_f,\n",
        "      'FPR_diff': FPR_m - FPR_f,\n",
        "      'fnr_barnard_pvalue': fnr_barnard.pvalue,\n",
        "      'fpr_barnard_pvalue': fpr_barnard.pvalue,\n",
        "      'beta2': beta2,\n",
        "      'beta2_pvalue': beta2_pvalue,\n",
        "      'accuracy_corrected': accuracy_corrected,\n",
        "      'roc_auc_corrected': roc_auc_corrected,\n",
        "      'FNR_corrected': FNR_corrected,\n",
        "      'FPR_corrected': FPR_corrected,\n",
        "      'accuracy_corrected_diff': accuracy_corrected_m - accuracy_corrected_f,\n",
        "      'roc_auc_corrected_diff': roc_auc_corrected_m - roc_auc_corrected_f,\n",
        "      'FNR_corrected_diff': FNR_corrected_m - FNR_corrected_f,\n",
        "      'FPR_corrected_diff': FPR_corrected_m - FPR_corrected_f\n",
        "  })\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "perf_metrics_df.to_csv(f'{PROJECT_ROOT}/results/perf_metrics_{N_RUNS}_runs.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90tUITGGNBds"
      },
      "source": [
        "# Results\n",
        "\n",
        "## Expected baseline disparity statistics\n",
        "\n",
        "| Metric | Mean | P value |\n",
        "|:--|--:|--:|\n",
        "| Accuracy disparity (%) | 0.32 | 0.50 |\n",
        "| ROC_AUC disparity (%) | 3.86 | <.01 |\n",
        "| FNR disparity (%) | -11.66 | <.01 |\n",
        "| FPR disparity (%) | 3.94 | <0.1 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAswEfghsMrV",
        "outputId": "5fc9cbd3-d5c1-4c0d-dfea-aba38753d5ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall performance---\n",
            "Accuracy: 0.859  (95% CI: 0.855, 0.863)\n",
            "ROC AUC: 0.926  (95% CI: 0.923, 0.929)\n",
            "FNR: 13.97  (95% CI: 13.29, 14.65)\n",
            "FPR: 14.24  (95% CI: 13.56, 14.92)\n",
            "\n",
            "\n",
            "|    | Metric        |   Mean % |   Std Dev % |     t-test |     P value |\n",
            "|---:|:--------------|---------:|------------:|-----------:|------------:|\n",
            "|  0 | accuracy_diff |     0.01 |        4.6  |  0.0218411 | 0.982619    |\n",
            "|  1 | roc_auc_diff  |     1.54 |        3.73 |  4.12083   | 7.84779e-05 |\n",
            "|  2 | FNR_diff      |   -12.18 |       12.33 | -9.88451   | 1.95412e-16 |\n",
            "|  3 | FPR_diff      |     5.15 |        7.55 |  6.82241   | 7.20108e-10 |\n",
            "\n",
            " Proportion of runs where a causal path between sex and prediction was detected: 89.0 %\n",
            "\n",
            " Association between detection of causal path and significant FNR disparity: \n",
            " 0.05745658835546476 (P-value = 0.8105620290006389)\n",
            "\n",
            " Association between detection of causal path and significant FPR disparity: \n",
            " 0.0 (P-value = 1.0)\n",
            "\n",
            "--- FNR Disparity Mitigation Analysis (N=100) ---\n",
            "Mean Absolute FNR Disparity BEFORE Correction: -0.1218\n",
            "Std Dev Absolute FNR Disparity BEFORE Correction: 0.1233\n",
            "--------------------------------------------------\n",
            "Mean Absolute FNR Disparity AFTER Correction: -0.1007\n",
            "Std Dev Absolute FNR Disparity AFTER Correction: 0.1188\n",
            "--------------------------------------------------\n",
            "Paired T-Statistic (t): -5.5935\n",
            "P-value: 0.000000\n",
            "Mean correction (absolute): 2.12%\n",
            "Mean correction (relative): 53.65%\n",
            "\n",
            "---Overall performance after correction---\n",
            "Accuracy: 0.859  (95% CI: 0.854, 0.863)\n",
            "ROC AUC: 0.923  (95% CI: 0.92, 0.926)\n",
            "FNR: 14.47  (95% CI: 13.74, 15.2)\n",
            "FPR: 13.85  (95% CI: 13.15, 14.56)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import ttest_1samp, ttest_rel\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2_contingency\n",
        "import pandas as pd\n",
        "\n",
        "# N_RUNS=100\n",
        "\n",
        "perf_metrics_df = pd.read_csv(f'{PROJECT_ROOT}/results/perf_metrics_{N_RUNS}_runs.csv')\n",
        "\n",
        "# OVERALL PERFORMANCE\n",
        "accuracy_ci = get_95_ci(perf_metrics_df['accuracy'])\n",
        "roc_auc_ci = get_95_ci(perf_metrics_df['roc_auc'])\n",
        "fnr_ci = get_95_ci(perf_metrics_df['FNR'])\n",
        "fpr_ci = get_95_ci(perf_metrics_df['FPR'])\n",
        "\n",
        "print('---Overall performance---')\n",
        "print(f'Accuracy: {round(perf_metrics_df[\"accuracy\"].mean(), 3)}\\\n",
        "  (95% CI: {round(accuracy_ci[0], 3)}, {round(accuracy_ci[1], 3)})')\n",
        "print(f'ROC AUC: {round(perf_metrics_df[\"roc_auc\"].mean(), 3)}\\\n",
        "  (95% CI: {round(roc_auc_ci[0], 3)}, {round(roc_auc_ci[1],3)})')\n",
        "print(f'FNR: {round(perf_metrics_df[\"FNR\"].mean()*100, 2)}\\\n",
        "  (95% CI: {round(fnr_ci[0]*100, 2)}, {round(fnr_ci[1]*100, 2)})')\n",
        "print(f'FPR: {round(perf_metrics_df[\"FPR\"].mean()*100, 2)}\\\n",
        "  (95% CI: {round(fpr_ci[0]*100, 2)}, {round(fpr_ci[1]*100, 2)})')\n",
        "print('\\n')\n",
        "\n",
        "# DISPARITY STATS, as per Straw et al\n",
        "# Does this experiment show the same statistical disparity across runs\n",
        "# as the original study?\n",
        "def disparity_stats(data, metric_diff):\n",
        "  mean = data[metric_diff].mean()\n",
        "  std = data[metric_diff].std()\n",
        "  t, p = ttest_1samp(data[metric_diff], popmean=0)\n",
        "  return [metric_diff, round(mean*100, 2), round(std*100, 2), t, p]\n",
        "\n",
        "disparity_stats_df = pd.DataFrame(\n",
        "    [disparity_stats(perf_metrics_df, 'accuracy_diff'),\n",
        "     disparity_stats(perf_metrics_df, 'roc_auc_diff'),\n",
        "     disparity_stats(perf_metrics_df, 'FNR_diff'),\n",
        "     disparity_stats(perf_metrics_df, 'FPR_diff')\n",
        "     ],\n",
        "    columns=['Metric', 'Mean %', 'Std Dev %', 't-test', 'P value'])\n",
        "\n",
        "print(disparity_stats_df.to_markdown())\n",
        "\n",
        "\n",
        "# HYPOTHESIS 1: Causal modelling (as per Hui and Lau's method)\n",
        "# will detect a statistically significant direct causal path\n",
        "# from the protected attribute (sex) to the prediction outcome\n",
        "\n",
        "# How reliably does the model detect significance in a single split?\n",
        "# Over the total number of runs, how many recorded a P-value for beta2 < 0.05\n",
        "causal_detected = perf_metrics_df['beta2_pvalue'] < 0.05\n",
        "runs_with_causal_path = perf_metrics_df[causal_detected]\n",
        "print(f'\\n Proportion of runs where a causal path between sex and prediction\\\n",
        " was detected: {round(len(runs_with_causal_path)/N_RUNS, 3)*100} %')\n",
        "\n",
        "# Contingency table analysis: how often the causal model flags a problem exactly\n",
        "# when the performance metrics show an inequitable outcome\n",
        "sig_fnr_disparity = perf_metrics_df['fnr_barnard_pvalue'] < 0.05\n",
        "Causal_FNR_disparity = pd.crosstab(causal_detected, sig_fnr_disparity,\n",
        "                                   rownames=['Causal Path Detected (beta2)'],\n",
        "                                   colnames=['Significant FNR Disparity (Barnard)'])\n",
        "\n",
        "sns.heatmap(Causal_FNR_disparity, annot=True, cmap=sns.color_palette('light:#D92B89', as_cmap=True))\n",
        "plt.title('Association between detection of causal path and significant FNR disparity')\n",
        "plt.savefig(f'{PROJECT_ROOT}/results/causal-FNR-association-heatmap', format='png')\n",
        "plt.clf()\n",
        "\n",
        "chi2_causal_FNR_disparity = chi2_contingency(Causal_FNR_disparity.values)\n",
        "print(f'\\n Association between detection of causal path and significant FNR disparity:\\\n",
        " \\n {chi2_causal_FNR_disparity.statistic} (P-value = {chi2_causal_FNR_disparity.pvalue})')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sig_fpr_disparity = perf_metrics_df['fpr_barnard_pvalue'] < 0.05\n",
        "Causal_FPR_disparity = pd.crosstab(causal_detected, sig_fpr_disparity,\n",
        "                                   rownames=['Causal Path Detected (beta2)'],\n",
        "                                   colnames=['Significant FPR Disparity (Barnard)'])\n",
        "\n",
        "sns.heatmap(Causal_FPR_disparity, annot=True, cmap=sns.color_palette('light:#D92B89', as_cmap=True))\n",
        "plt.title('Association between detection of causal path and significant FPR disparity')\n",
        "plt.savefig(f'{PROJECT_ROOT}/results/causal-FPR-association-heatmap', format='png')\n",
        "plt.clf()\n",
        "\n",
        "chi2_causal_FPR_disparity = chi2_contingency(Causal_FPR_disparity.values)\n",
        "print(f'\\n Association between detection of causal path and significant FPR disparity:\\\n",
        " \\n {chi2_causal_FPR_disparity.statistic} (P-value = {chi2_causal_FPR_disparity.pvalue})')\n",
        "\n",
        "# Correlation between disparity metrics\n",
        "corr_matrix = perf_metrics_df[['accuracy_diff', 'roc_auc_diff', 'FNR_diff', 'FPR_diff', 'beta2']].corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=sns.diverging_palette(250, 250, center='light', as_cmap=True))\n",
        "plt.savefig(f'{PROJECT_ROOT}/results/disparity-metrics-correlation', format='png')\n",
        "plt.close()\n",
        "\n",
        "# HYPOTHESIS 2: mitigating the detected causal path\n",
        "# will reduce the observed sex-based performance disparity (FNR difference)\n",
        "# in the cardiac disease prediction model\n",
        "\n",
        "\n",
        "# We analyse the statistical significance of the correction in the runs where\n",
        "# a causal path was detected, with paired-sample t-test on the FNR difference\n",
        "# before and after causal mitigation\n",
        "fnr_causal_correction_ttest = ttest_rel(perf_metrics_df['FNR_diff'],\n",
        "                                         perf_metrics_df['FNR_corrected_diff'],\n",
        "                                         alternative='less')\n",
        "print(\"\\n--- FNR Disparity Mitigation Analysis (N=100) ---\")\n",
        "print(f\"Mean Absolute FNR Disparity BEFORE Correction:\\\n",
        " {perf_metrics_df['FNR_diff'].mean():.4f}\")\n",
        "print(f\"Std Dev Absolute FNR Disparity BEFORE Correction:\\\n",
        " {perf_metrics_df['FNR_diff'].std():.4f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Mean Absolute FNR Disparity AFTER Correction:\\\n",
        " {perf_metrics_df['FNR_corrected_diff'].mean():.4f}\")\n",
        "print(f\"Std Dev Absolute FNR Disparity AFTER Correction:\\\n",
        " {perf_metrics_df['FNR_corrected_diff'].std():.4f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Paired T-Statistic (t): {fnr_causal_correction_ttest.statistic:.4f}\")\n",
        "print(f\"P-value: {fnr_causal_correction_ttest.pvalue:.6f}\")\n",
        "\n",
        "perf_metrics_df['FNR_correction_abs'] = perf_metrics_df['FNR_corrected_diff'] \\\n",
        "  - perf_metrics_df['FNR_diff']\n",
        "perf_metrics_df['FNR_correction_rel'] = perf_metrics_df['FNR_correction_abs'] \\\n",
        "  / perf_metrics_df['FNR_diff'].abs()\n",
        "\n",
        "print(f'Mean correction (absolute): {perf_metrics_df[\"FNR_correction_abs\"].mean()*100:.2f}%')\n",
        "print(f'Mean correction (relative): {perf_metrics_df[\"FNR_correction_rel\"].mean()*100:.2f}%')\n",
        "\n",
        "#Impact of the correction on the overall performance\n",
        "accuracy_corrected_ci = get_95_ci(perf_metrics_df['accuracy_corrected'])\n",
        "roc_auc_corrected_ci = get_95_ci(perf_metrics_df['roc_auc_corrected'])\n",
        "fnr_corrected_ci = get_95_ci(perf_metrics_df['FNR_corrected'])\n",
        "fpr_corrected_ci = get_95_ci(perf_metrics_df['FPR_corrected'])\n",
        "\n",
        "print('\\n---Overall performance after correction---')\n",
        "print(f'Accuracy: {round(perf_metrics_df[\"accuracy_corrected\"].mean(), 3)}\\\n",
        "  (95% CI: {round(accuracy_corrected_ci[0], 3)}, {round(accuracy_corrected_ci[1], 3)})')\n",
        "print(f'ROC AUC: {round(perf_metrics_df[\"roc_auc_corrected\"].mean(), 3)}\\\n",
        "  (95% CI: {round(roc_auc_corrected_ci[0], 3)}, {round(roc_auc_corrected_ci[1],3)})')\n",
        "print(f'FNR: {round(perf_metrics_df[\"FNR_corrected\"].mean()*100, 2)}\\\n",
        "  (95% CI: {round(fnr_corrected_ci[0]*100, 2)}, {round(fnr_corrected_ci[1]*100, 2)})')\n",
        "print(f'FPR: {round(perf_metrics_df[\"FPR_corrected\"].mean()*100, 2)}\\\n",
        "  (95% CI: {round(fpr_corrected_ci[0]*100, 2)}, {round(fpr_corrected_ci[1]*100, 2)})')\n",
        "print('\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
