{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ec5acca",
      "metadata": {
        "id": "3ec5acca"
      },
      "source": [
        "# Training a counterfactually fair CAD model\n",
        "\n",
        "## Counterfactual Fairness\n",
        "\n",
        "Attempts to mitigate bias in a model by simply removing sensitive attributes from its training, i.e. fairness by unawareness, often fails due to bias 'leaking' through causal relationships between the sensitive attribute and other features retained in the data. The counterfactual fairness approach introduced by Kusner et al. (2017, in Advances in Neural Information Processing Systems, https://proceedings.neurips.cc/paper_files/paper/2017/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf) addresses this limitation by deconvoluting the biased observed variables into a fair set of unbiased latent variables. It allows the model to only learn from information that is independent from the protected attribute, and neutralise both direct and proxy bias pathways.\n",
        "\n",
        "### Notations and definitions\n",
        "\n",
        "we adopt the following notations consistent with the Pearlian causal framework used by Kusner et al.:\n",
        "\n",
        "- $S$ **Protected attribute**: The sensitive variable we wish to be fair toward\n",
        "- $X$ **Observed features**: The set of features available in the dataset (e.g. Blood Pressure, Cholesterol)\n",
        "- $U$ **Latent (unobserved) variables**: Unobserved variables that are independent of the protected attribute $A$\n",
        "- $Y$ **Target**: The outcome we are predicting (e.g. Presence of CAD)\n",
        "- $Y_{S \\leftarrow s}$: The value of $Y$ under a counterfactual intervention where $S$ is set to $s$\n",
        "- $M = (U, V, F)$ a causal model corresponding to the observed data, where $V \\equiv X \\cup Y \\cup S$, and $F$ is the set of structural equations of the model\n",
        "\n",
        "**Counterfactual Fairness:** A predictor $\\hat{Y}$ is counterfactually fair if, for a specific individual, the probability distribution of the prediction is the same in the actual world as it would be in a counterfactual world where their protected attribute (e.g., Sex) was different.\n",
        "\n",
        "Formally, for any value $a'$ of the protected attribute $A$:$$P(\\hat{Y}_{S \\leftarrow s} = y \\mid X=x, S=s) = P(\\hat{Y}_{S \\leftarrow s'} = y \\mid X=x, S=s')$$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## The experiment\n",
        "\n",
        "Using the fairness-unaware models trained to predict Cardiovascular Disease in Straw et al. (2024, doi: [10.2196/46936](https://doi.org/10.2196/46936)) as baseline models, we will apply the fairness algorithm proposed by Kusner et al. to train a fair CAD predictor.\n",
        "\n",
        "### The target bias\n",
        "While Kusner focus on mitigating bias on tasks where the protected attribute should have no influence on the target outcome (e.g. sex and exam results), the clinical domain brings a new challenge. Indeed, protected attributes such as sex or race often encompass two variables: the clinically relevant biological attribute which can cause a disease to present differently across individuals, and the sociological attribute which has societal factors that can influence healthcare access, physician perception, diagnosis and care. A clinical outcome might be influenced by the former but should remain independent of the latter.\n",
        "\n",
        "If we aim for fairness based on the high-level sex attribute, we risk removing legitimate clinical signals and degrading diagnostic accuracy. Therefore, our objective in experiment is to make the model counterfactually fair with regards to **sociological sex**.\n",
        "\n",
        "### Hypothesis\n",
        "\n",
        "By using counterfactual inference to model latent variables that are independent of the protected attribute, we can build a predictor that satisfies counterfactual fairness (i.e. ensuring that an individualâ€™s predicted risk of CAD remains invariant to their sociological sex), while maintaining clinically acceptable predictive performance and reducing the False Negative Rate (FNR) disparity observed in baseline models.\n",
        "\n",
        "---\n",
        "\n",
        "## Causal models\n",
        "\n",
        "From the feature set observed in the [Heart Disease (CAD) dataset](https://ieee-dataport.org/open-access/heart-disease-dataset-comprehensive), using clinical knowledge in the literature and strong assumptions, we create two causal models that we will compare in this experiment:\n",
        "\n",
        "### Latent variables model\n",
        "\n",
        "We hypothesise that clinical features in the CAD dataset are manifestations of a patient's **Innate Cardiovascular Health**, which we define as our fair latent variable $U$. It is independent of the protected attributes $S_{bio}$ and $S_{soc}$.\n",
        "\n",
        "We postulate thatsubjective symptoms and clinician-dependent interpretations are influenced by Sociological Sex ($S_{soc}$). This creates an unfair pathway where the recorded value of a feature is not solely a manifestation of the patient's physiological state, but is also a product of external factors:\n",
        "- Reporting bias: how a patient describes symptoms like chest pain based on gendered expectations\n",
        "- Diagnostic bias: how a clinician interprets those symptoms, potentially mislabeling 'atypical' presentations in women\n",
        "\n",
        "We assume that objective biomarkers such as cholesterol, maximum heart rate, resting blood pressure, fasting blood sugar, and measurements related to the ECG ST slope, are only influenced by the **biological sex** ($S_{bio}$), and are therefore fair pathways for the predictor.\n",
        "\n",
        "Age is considered as the sole independent variable from $S_{bio}$ and $S_{soc}$.\n",
        "\n",
        "\n",
        "\n",
        "### Additive error model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import userdata\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  PROJECT_ROOT = userdata.get('PROJECT_ROOT')\n",
        "except ImportError:\n",
        "  PROJECT_ROOT = '/'"
      ],
      "metadata": {
        "id": "Gxjr-eCtewL0",
        "outputId": "d557e785-9304-49a7-8bb2-9d4b5e192c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Gxjr-eCtewL0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kbmETDXCfWz9"
      },
      "id": "kbmETDXCfWz9",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart_disease = pd.read_csv(f'{PROJECT_ROOT}data/heart_disease_cleveland_hungary.csv')\n",
        "\n",
        "# Remove duplicates and null values, as per Straw et al.\n",
        "\n",
        "rows_to_drop  = (heart_disease['cholesterol'] == 0) | (heart_disease['resting bp s'] == 0) | (heart_disease.duplicated(keep='first'))\n",
        "heart_disease.drop(heart_disease[rows_to_drop].index, inplace=True)"
      ],
      "metadata": {
        "id": "VyTAePF0fRhb"
      },
      "id": "VyTAePF0fRhb",
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}