{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e2b9f87",
      "metadata": {
        "id": "8e2b9f87"
      },
      "source": [
        "# Classifier training\n",
        "\n",
        "**Inputs:**\n",
        "- data/heart_disease_cleaned.csv\n",
        "- data/fair_heart_disease_hybrid.csv\n",
        "- data/counterfactual_heart_disease_hybrid.csv\n",
        "\n",
        "**Outputs:**\n",
        "- results/perf_metrics.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pmUinkV6hNrV",
      "metadata": {
        "id": "pmUinkV6hNrV"
      },
      "source": [
        "## Setup and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gxjr-eCtewL0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxjr-eCtewL0",
        "outputId": "8040dde3-6d3e-47a1-bfa8-205594d4da2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import userdata\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  PROJECT_ROOT = userdata.get('PROJECT_ROOT')\n",
        "else:\n",
        "  PROJECT_ROOT = '../'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "kbmETDXCfWz9",
      "metadata": {
        "id": "kbmETDXCfWz9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import output\n",
        "# output.enable_custom_widget_manager()\n",
        "output.disable_custom_widget_manager()\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_context('paper', font_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "tpVnZIxKzo7d",
      "metadata": {
        "id": "tpVnZIxKzo7d"
      },
      "outputs": [],
      "source": [
        "heart_disease = pd.read_csv(f'{PROJECT_ROOT}/data/heart_disease_cleaned.csv')\n",
        "fair_heart_disease = pd.read_csv(f'{PROJECT_ROOT}/data/fair_heart_disease_hybrid.csv')\n",
        "cf_heart_disease = pd.read_csv(f'{PROJECT_ROOT}/data/cf_heart_disease_hybrid.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_kUqDR4Nh5tG",
      "metadata": {
        "id": "_kUqDR4Nh5tG"
      },
      "source": [
        "### Function library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "314YeMBPXwac",
      "metadata": {
        "id": "314YeMBPXwac"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,\\\n",
        " recall_score, roc_auc_score\n",
        "\n",
        "def train_random_forest(X_train, y_train, X_test, y_test):\n",
        "  '''\n",
        "    Trains a sklearn RandomForestClassifier on the given training data,\\\n",
        "     optimised hyperparameters with 3-fold GridSearchCV\n",
        "\n",
        "     Inputs:\n",
        "       X_train: training features\n",
        "       y_train: training labels\n",
        "       X_test: test features\n",
        "       y_test: test labels\n",
        "\n",
        "     Outputs:\n",
        "       rf: trained RandomForestClassifier\n",
        "       y_pred: predicted labels\n",
        "       y_pred_proba: predicted probabilities\n",
        "  '''\n",
        "  param_grid = {\n",
        "    \"max_depth\": [5, 10, 20, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "    \"min_samples_leaf\": [1, 2]\n",
        "  }\n",
        "\n",
        "  #create the RF classifier\n",
        "  rf = RandomForestClassifier(random_state=4, n_estimators=100)\n",
        "\n",
        "  #create the grid search\n",
        "  rf_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
        "                               n_iter=10, scoring='roc_auc',\n",
        "                               cv=3, n_jobs=-1, random_state=4)\n",
        "\n",
        "  #fit the grid search\n",
        "  rf_search.fit(X_train, y_train)\n",
        "  y_pred = rf_search.predict(X_test)\n",
        "  y_pred_proba = rf_search.predict_proba(X_test)[:,1]\n",
        "\n",
        "  return [rf_search, y_pred, y_pred_proba]\n",
        "\n",
        "def get_perf_metrics(y_true, y_pred, y_pred_proba):\n",
        "  '''\n",
        "    Calculates the performance metrics for a given set of predictions.\n",
        "\n",
        "    Inputs\n",
        "      y_true: true labels\n",
        "      y_pred: predicted labels\n",
        "      y_pred_proba: predicted probabilities\n",
        "\n",
        "    Outputs\n",
        "      accuracy: accuracy score\n",
        "      roc_auc: ROC AUC (Receiver Operating Characteristic Area Under the Curve)\n",
        "      FNR: False Negative Rate\n",
        "      FPR: False Positive Rate\n",
        "      tn: True Negatives\n",
        "      fp: False Positives\n",
        "      fn: False Negatives\n",
        "      tp: True Positives\n",
        "  '''\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  FNR = fn / (fn + tp)\n",
        "  FPR = fp / (fp + tn)\n",
        "\n",
        "  return [accuracy, roc_auc, FNR, FPR, tn, fp, fn, tp]\n",
        "\n",
        "def get_counterfactual_flips(y_pred, y_cf_total, y_cf_path):\n",
        "  '''\n",
        "    Calculates the frequency of counterfactual flips for a given set of predictions.\n",
        "\n",
        "    Inputs\n",
        "      y_pred: predictions made on the factual dataset as a numpy array\n",
        "      y_cf_total: predictions made on the corresponding TOTAL EFFECT counterfactual dataset as a numpy array\n",
        "      y_cf_path: predictions made on the corresponding PATHWAY EFFECT counterfactual dataset as a numpy array\n",
        "\n",
        "    Outputs\n",
        "      pos_flipped_full: frequency of counterfactual flips from y=0 to y=1 for both TOTAL and PATHWAY effect\n",
        "      pos_flipped_total: frequency of counterfactual flips from y=0 to y=1 for TOTAL effect only\n",
        "      pos_flipped_path: frequency of counterfactual flips from y=0 to y=1 for PATHWAY effect only\n",
        "      neg_flipped_full: frequency of counterfactual flips from y=1 to y=0 for both TOTAL and PATHWAY effect\n",
        "      neg_flipped_total: frequency of counterfactual flips from y=1 to y=0 for TOTAL effect only\n",
        "      neg_flipped_path: frequency of counterfactual flips from y=1 to y=0 for PATHWAY effect only\n",
        "  '''\n",
        "  pos_flipped_full = np.sum((y_pred == 0) & (y_cf_total == 1) & (y_cf_path == 1)) / len(y_pred)\n",
        "  pos_flipped_total = np.sum((y_pred == 0) & (y_cf_total == 1)  & (y_cf_path == 0)) / len(y_pred)\n",
        "  pos_flipped_path = np.sum((y_pred == 0) & (y_cf_total == 0) & (y_cf_path == 1)) / len(y_pred)\n",
        "  neg_flipped_full = np.sum((y_pred == 1) & (y_cf_total == 0) & (y_cf_path == 0)) / len(y_pred)\n",
        "  neg_flipped_total = np.sum((y_pred == 1) & (y_cf_total == 0)  & (y_cf_path == 1)) / len(y_pred)\n",
        "  neg_flipped_path = np.sum((y_pred == 1) & (y_cf_total == 1) & (y_cf_path == 0)) / len(y_pred)\n",
        "  return [pos_flipped_full, pos_flipped_total, pos_flipped_path,\n",
        "          neg_flipped_full, neg_flipped_total, neg_flipped_path]\n",
        "\n",
        "def get_causal_metrics(y_pred, y_cf_pred):\n",
        "    '''\n",
        "      Calculates the number and frequency of counterfactual flips\\\n",
        "       for a given set of predictions and their counterfactual predictions.\n",
        "\n",
        "      Inputs\n",
        "        y_pred: predictions made on the factual dataset as a numpy array\n",
        "        y_cf_pred: predictions made on the corresponding counterfactual dataset as a numpy array\n",
        "\n",
        "      Outputs\n",
        "        num_pos_flips: number of counterfactual flips from y=0 to y=1\n",
        "        num_neg_flips: number of counterfactual flips from y=1 to y=0\n",
        "        freq_pos_flips: frequency of counterfactual flips from y=0 to y=1\n",
        "        freq_neg_flips: frequency of counterfactual flips from y=1 to y=0\n",
        "    '''\n",
        "    num_pos_flips = np.sum((y_pred == 0) & (y_cf_pred == 1))\n",
        "    num_neg_flips = np.sum((y_pred == 1) & (y_cf_pred == 0))\n",
        "    freq_pos_flips = num_pos_flips / len(y_pred)\n",
        "    freq_neg_flips = num_neg_flips / len(y_pred)\n",
        "\n",
        "    return [num_pos_flips, num_neg_flips, freq_pos_flips, freq_neg_flips]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2GDwpV-a0JpX",
      "metadata": {
        "id": "2GDwpV-a0JpX"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ary5M8NW0K_m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ary5M8NW0K_m",
        "outputId": "a7bdfdae-4376-4320-dae5-4a9a891b8a60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running simulations:   4%|‚ñç         | 2/50 [00:56<22:20, 27.92s/it]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from scipy.stats import barnard_exact\n",
        "\n",
        "# baseline features and target class\n",
        "\n",
        "X = heart_disease.drop(['cvd'], axis=1)\n",
        "y = heart_disease['cvd']\n",
        "X_cf = cf_heart_disease.drop(['cvd','U'], axis=1)\n",
        "y_cf = cf_heart_disease['cvd']\n",
        "\n",
        "# Bootstrapping approach with N_RUNS runs and a 70/30 split for training and test\n",
        "N_RUNS = 50\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=N_RUNS, test_size=0.3, random_state=42)\n",
        "\n",
        "perf_metrics = []\n",
        "\n",
        "for i, (train_index, test_index) in tqdm(enumerate(sss.split(X, y)), total=N_RUNS, desc=\"Running simulations\"):\n",
        "\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Create the equivalent fair training and test sets\n",
        "  fair_X_train = fair_heart_disease.loc[fair_heart_disease['ID'].isin(train_index)].drop(['cvd', 'ID', 'sex'], axis=1)\n",
        "  fair_X_test = fair_heart_disease.loc[fair_heart_disease['ID'].isin(test_index)].drop(['cvd', 'ID', 'sex'], axis=1)\n",
        "  fair_y_train = fair_heart_disease.loc[fair_heart_disease['ID'].isin(train_index), 'cvd']\n",
        "  fair_y_test = fair_heart_disease.loc[fair_heart_disease['ID'].isin(test_index), 'cvd']\n",
        "\n",
        "  # Train the baseline and fair models\n",
        "  rf, y_pred, y_pred_proba = train_random_forest(X_train, y_train, X_test, y_test)\n",
        "  fair_rf, fair_y_pred, fair_y_pred_proba = train_random_forest(\n",
        "      fair_X_train, fair_y_train, fair_X_test, fair_y_test)\n",
        "\n",
        "  #GLOBAL PERFORMANCE METRICS\n",
        "  accuracy, roc_auc, FNR, FPR,*_ = get_perf_metrics(y_test, y_pred, y_pred_proba)\n",
        "  fair_accuracy, fair_roc_auc, fair_FNR, fair_FPR,*_ = get_perf_metrics(fair_y_test, fair_y_pred, fair_y_pred_proba)\n",
        "\n",
        "  # COUNTERFACTUAL PREDICTIONS for the baseline model\n",
        "\n",
        "  # 1. TOTAL: Flip Ssoc through ECG, ANG, CP and flip the sex feature, while keeping other variables unchanged\n",
        "  # = what is the total effect of flipping the social sex label and the sociologically-biased pathways?\n",
        "  X_cf_1_test = X_cf.iloc[test_index].copy()\n",
        "  y_cf_1_test = y_cf.iloc[test_index].copy()\n",
        "  y_cf_1_pred = rf.predict(X_cf_1_test)\n",
        "\n",
        "  # 2. PATHWAY-SPECIFIC: Flip Ssoc through ECG, ANG, CP but keep factual sex feature and other variables unchanged\n",
        "  # = What is the prediction for the individual if their symptoms had been\n",
        "  # reported and interpreted as the other sex\n",
        "  X_cf_2_test = X_cf.iloc[test_index].copy()\n",
        "  X_cf_2_test['sex'] = X_test['sex'].values\n",
        "  y_cf_2_test = y_cf.iloc[test_index].copy()\n",
        "  y_cf_2_pred = rf.predict(X_cf_2_test)\n",
        "\n",
        "  # STRATIFIED PERFORMANCE AND FAIRNESS\n",
        "  # Baseline audit dataset\n",
        "  baseline_audit_df = X_test.copy()\n",
        "  baseline_audit_df['y_true'] = y_test\n",
        "  baseline_audit_df['y_pred'] = y_pred\n",
        "  baseline_audit_df['y_pred_proba'] = y_pred_proba\n",
        "  baseline_audit_df['y_cf_1_pred'] = y_cf_1_pred\n",
        "  baseline_audit_df['y_cf_2_pred'] = y_cf_2_pred\n",
        "\n",
        "  baseline_male_df = baseline_audit_df[baseline_audit_df['sex'] == 1]\n",
        "  baseline_female_df = baseline_audit_df[baseline_audit_df['sex'] == 0]\n",
        "\n",
        "  # Fair audit dataset\n",
        "  fair_audit_df = fair_heart_disease.loc[fair_heart_disease['ID'].isin(test_index)].copy()\n",
        "  fair_audit_df['y_true'] = fair_y_test\n",
        "  fair_audit_df['y_pred'] = fair_y_pred\n",
        "  fair_audit_df['y_pred_proba'] = fair_y_pred_proba\n",
        "  fair_male_df = fair_audit_df[fair_audit_df['sex'] == 1]\n",
        "  fair_female_df = fair_audit_df[fair_audit_df['sex'] == 0]\n",
        "\n",
        "  ### STRATIFIED PERFORMANCE AUDIT\n",
        "  # Baseline Model:\n",
        "  accuracy_m, roc_auc_m, FNR_m, FPR_m, tn_m, fp_m, fn_m, tp_m = get_perf_metrics(\n",
        "      baseline_male_df['y_true'],\n",
        "      baseline_male_df['y_pred'],\n",
        "      baseline_male_df['y_pred_proba'])\n",
        "\n",
        "  accuracy_f, roc_auc_f, FNR_f, FPR_f, tn_f, fp_f, fn_f, tp_f = get_perf_metrics(\n",
        "      baseline_female_df['y_true'],\n",
        "      baseline_female_df['y_pred'],\n",
        "      baseline_female_df['y_pred_proba'])\n",
        "\n",
        "  # Fair Model before correction of direct bias:\n",
        "  fair_accuracy_m, fair_roc_auc_m, fair_FNR_m, fair_FPR_m, *_ = get_perf_metrics(\n",
        "      fair_male_df['y_true'],\n",
        "      fair_male_df['y_pred'],\n",
        "      fair_male_df['y_pred_proba'])\n",
        "\n",
        "  fair_accuracy_f, fair_roc_auc_f, fair_FNR_f, fair_FPR_f, *_ = get_perf_metrics(\n",
        "      fair_female_df['y_true'],\n",
        "      fair_female_df['y_pred'],\n",
        "      fair_female_df['y_pred_proba'])\n",
        "\n",
        "  ### COUNTERFACTUAL FAIRNESS METRICS on the baseline model\n",
        "\n",
        "  pos_flipped_full_m, pos_flipped_total_m, pos_flipped_path_m,\\\n",
        "   neg_flipped_full_m, neg_flipped_total_m, neg_flipped_path_m = get_counterfactual_flips(\n",
        "      baseline_male_df['y_pred'],\n",
        "      baseline_male_df['y_cf_1_pred'],\n",
        "      baseline_male_df['y_cf_2_pred'])\n",
        "\n",
        "  pos_flipped_full_f, pos_flipped_total_f, pos_flipped_path_f,\\\n",
        "   neg_flipped_full_f, neg_flipped_total_f, neg_flipped_path_f = get_counterfactual_flips(\n",
        "      baseline_female_df['y_pred'],\n",
        "      baseline_female_df['y_cf_1_pred'],\n",
        "      baseline_female_df['y_cf_2_pred'])\n",
        "\n",
        "  perf_metrics.append({\n",
        "      'run': i,\n",
        "      'accuracy': accuracy,\n",
        "      'roc_auc': roc_auc,\n",
        "      'FNR': FNR,\n",
        "      'FPR': FPR,\n",
        "      'fair_accuracy': fair_accuracy,\n",
        "      'fair_roc_auc': fair_roc_auc,\n",
        "      'fair_FNR': fair_FNR,\n",
        "      'fair_FPR': fair_FPR,\n",
        "      'accuracy_m': accuracy_m,\n",
        "      'accuracy_f': accuracy_f,\n",
        "      'accuracy_diff': accuracy_m - accuracy_f,\n",
        "      'roc_auc_m': roc_auc_m,\n",
        "      'roc_auc_f': roc_auc_f,\n",
        "      'roc_auc_diff': roc_auc_m - roc_auc_f,\n",
        "      'FNR_m': FNR_m,\n",
        "      'FNR_f': FNR_f,\n",
        "      'FNR_diff': FNR_m - FNR_f,\n",
        "      'FPR_m': FPR_m,\n",
        "      'FPR_f': FPR_f,\n",
        "      'FPR_diff': FPR_m - FPR_f,\n",
        "      'fair_accuracy_m': fair_accuracy_m,\n",
        "      'fair_accuracy_f': fair_accuracy_f,\n",
        "      'fair_accuracy_diff': fair_accuracy_m - fair_accuracy_f,\n",
        "      'fair_roc_auc_m': fair_roc_auc_m,\n",
        "      'fair_roc_auc_f': fair_roc_auc_f,\n",
        "      'fair_roc_auc_diff': fair_roc_auc_m - fair_roc_auc_f,\n",
        "      'fair_FNR_m': fair_FNR_m,\n",
        "      'fair_FNR_f': fair_FNR_f,\n",
        "      'fair_FNR_diff': fair_FNR_m - fair_FNR_f,\n",
        "      'fair_FPR_m': fair_FPR_m,\n",
        "      'fair_FPR_f': fair_FPR_f,\n",
        "      'fair_FPR_diff': fair_FPR_m - fair_FPR_f,\n",
        "      'pos_flipped_full_m': pos_flipped_full_m,\n",
        "      'pos_flipped_full_f': pos_flipped_full_f,\n",
        "      'pos_flipped_total_m': pos_flipped_total_m,\n",
        "      'pos_flipped_total_f': pos_flipped_total_f,\n",
        "      'pos_flipped_path_m': pos_flipped_path_m,\n",
        "      'pos_flipped_path_f': pos_flipped_path_f,\n",
        "      'neg_flipped_full_m': neg_flipped_full_m,\n",
        "      'neg_flipped_full_f': neg_flipped_full_f,\n",
        "      'neg_flipped_total_m': neg_flipped_total_m,\n",
        "      'neg_flipped_total_f': neg_flipped_total_f,\n",
        "      'neg_flipped_path_m': neg_flipped_path_m,\n",
        "      'neg_flipped_path_f': neg_flipped_path_f\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ZU95kE0P0_",
      "metadata": {
        "id": "d6ZU95kE0P0_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "save_path = f'{PROJECT_ROOT}/results'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "date_str = datetime.datetime.now().strftime('%Y-%m-%d_%H%M')\n",
        "perf_metrics_df.to_csv(f'{save_path}/perf_metrics_hybrid_{N_RUNS}_runs_{date_str}.csv')\n",
        "print('Performance metrics saved')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
