{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8e2b9f87",
      "metadata": {
        "id": "8e2b9f87"
      },
      "source": [
        "# Classifier training\n",
        "\n",
        "**Inputs:**\n",
        "- data/heart_disease_cleaned.csv\n",
        "- data/fair_heart_disease_full.csv\n",
        "- data/counterfactual_heart_disease_full.csv\n",
        "\n",
        "**Outputs:**\n",
        "- results/perf_metrics.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pmUinkV6hNrV",
      "metadata": {
        "id": "pmUinkV6hNrV"
      },
      "source": [
        "## Setup and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gxjr-eCtewL0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxjr-eCtewL0",
        "outputId": "f25d28e0-4eef-436b-df3b-c53cf5c95738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import userdata\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  PROJECT_ROOT = userdata.get('PROJECT_ROOT')\n",
        "else:\n",
        "  PROJECT_ROOT = '../'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kbmETDXCfWz9",
      "metadata": {
        "id": "kbmETDXCfWz9"
      },
      "outputs": [],
      "source": [
        "!pip install -q semopy\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from google.colab import output\n",
        "# output.enable_custom_widget_manager()\n",
        "output.disable_custom_widget_manager()\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "sns.set_context('paper', font_scale=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tpVnZIxKzo7d",
      "metadata": {
        "id": "tpVnZIxKzo7d"
      },
      "outputs": [],
      "source": [
        "heart_disease = pd.read_csv(f'{PROJECT_ROOT}/data/heart_disease_cleaned.csv')\n",
        "fair_heart_disease = pd.read_csv(f'{PROJECT_ROOT}/data/fair_heart_disease_full.csv')\n",
        "cf_heart_disease = pd.read_csv(f'{PROJECT_ROOT}/data/cf_heart_disease_full.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_kUqDR4Nh5tG",
      "metadata": {
        "id": "_kUqDR4Nh5tG"
      },
      "source": [
        "### Function library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314YeMBPXwac",
      "metadata": {
        "id": "314YeMBPXwac"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score,\\\n",
        " recall_score, roc_auc_score\n",
        "import semopy\n",
        "\n",
        "def train_random_forest(X_train, y_train, X_test, y_test):\n",
        "  '''\n",
        "    Trains a sklearn RandomForestClassifier on the given training data,\\\n",
        "     optimised hyperparameters with 3-fold GridSearchCV\n",
        "\n",
        "     Inputs:\n",
        "       X_train: training features\n",
        "       y_train: training labels\n",
        "       X_test: test features\n",
        "       y_test: test labels\n",
        "\n",
        "     Outputs:\n",
        "       rf: trained RandomForestClassifier\n",
        "       y_pred: predicted labels\n",
        "       y_pred_proba: predicted probabilities\n",
        "  '''\n",
        "  param_grid = {\n",
        "    \"max_depth\": [5, 10, 20, None],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"],\n",
        "    \"min_samples_split\": [2, 5],\n",
        "    \"min_samples_leaf\": [1, 2]\n",
        "  }\n",
        "\n",
        "  #create the RF classifier\n",
        "  rf = RandomForestClassifier(random_state=4, n_estimators=100)\n",
        "\n",
        "  #create the grid search\n",
        "  rf_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid,\n",
        "                               n_iter=10, scoring='roc_auc',\n",
        "                               cv=3, n_jobs=-1, random_state=4)\n",
        "\n",
        "  #fit the grid search\n",
        "  rf_search.fit(X_train, y_train)\n",
        "  y_pred = rf_search.predict(X_test)\n",
        "  y_pred_proba = rf_search.predict_proba(X_test)[:,1]\n",
        "\n",
        "  return [rf_search, y_pred, y_pred_proba]\n",
        "\n",
        "def get_perf_metrics(y_true, y_pred, y_pred_proba):\n",
        "  '''\n",
        "    Calculates the performance metrics for a given set of predictions.\n",
        "\n",
        "    Inputs\n",
        "      y_true: true labels\n",
        "      y_pred: predicted labels\n",
        "      y_pred_proba: predicted probabilities\n",
        "\n",
        "    Outputs\n",
        "      accuracy: accuracy score\n",
        "      roc_auc: ROC AUC (Receiver Operating Characteristic Area Under the Curve)\n",
        "      FNR: False Negative Rate\n",
        "      FPR: False Positive Rate\n",
        "      tn: True Negatives\n",
        "      fp: False Positives\n",
        "      fn: False Negatives\n",
        "      tp: True Positives\n",
        "  '''\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  FNR = fn / (fn + tp)\n",
        "  FPR = fp / (fp + tn)\n",
        "\n",
        "  return [accuracy, roc_auc, FNR, FPR, tn, fp, fn, tp]\n",
        "\n",
        "def get_causal_model_params(X_train, y_train, y_pred_proba, protected_attribute):\n",
        "  '''\n",
        "    Trains a semopy causal model on the given training data and predictions,\\\n",
        "     for the following linear causal model:\\\n",
        "      y_pred ~ beta0 + beta1*y_true + beta2*protected_attribute,\\\n",
        "     to identify the causal relationship between the protected attribute\\\n",
        "      and the predicted outcome.\n",
        "\n",
        "     Inputs\n",
        "       X_train: training features\n",
        "       y_train: training labels\n",
        "       y_pred_proba: predicted probabilities\n",
        "       protected_attribute: name of the protected attribute\n",
        "\n",
        "     Outputs\n",
        "       beta2: coefficient of the causal relationship between\\\n",
        "        the protected attribute and the predicted outcome\n",
        "       beta2_pvalue: p-value of the causal relationship\n",
        "  '''\n",
        "  causal_features = pd.DataFrame()\n",
        "  causal_features['protected_attribute'] = X_train[protected_attribute]\n",
        "  causal_features['y_true'] = y_train\n",
        "  causal_features['y_pred'] = y_pred_proba\n",
        "\n",
        "  model_desc='''\n",
        "    y_true ~ protected_attribute\n",
        "    y_pred ~ y_true + protected_attribute\n",
        "  '''\n",
        "\n",
        "  causal_model = semopy.Model(model_desc)\n",
        "  causal_model.fit(causal_features)\n",
        "  causal_params = causal_model.inspect()\n",
        "\n",
        "  # Retrieve the coefficients of the causal model\n",
        "  beta2 = causal_params.loc[(causal_params.rval == \"protected_attribute\") &\n",
        "                            (causal_params.lval == \"y_pred\"),'Estimate'].values[0]\n",
        "  beta2_pvalue = causal_params.loc[(causal_params.rval == \"protected_attribute\") &\n",
        "                            (causal_params.lval == \"y_pred\"),'p-value'].values[0]\n",
        "\n",
        "  return [beta2, beta2_pvalue]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2GDwpV-a0JpX",
      "metadata": {
        "id": "2GDwpV-a0JpX"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ary5M8NW0K_m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ary5M8NW0K_m",
        "outputId": "79b8264e-ea2a-4275-8af6-1c5ec15353c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running simulations: 100%|██████████| 50/50 [26:06<00:00, 31.32s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from scipy.stats import barnard_exact\n",
        "\n",
        "# baseline features and target class\n",
        "\n",
        "X = heart_disease.drop(['cvd'], axis=1)\n",
        "y = heart_disease['cvd']\n",
        "X_cf = cf_heart_disease.drop(['cvd','U'], axis=1)\n",
        "y_cf = cf_heart_disease['cvd']\n",
        "\n",
        "# Bootstrapping approach with N_RUNS runs and a 70/30 split for training and test\n",
        "N_RUNS = 50\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=N_RUNS, test_size=0.3, random_state=42)\n",
        "\n",
        "perf_metrics = []\n",
        "\n",
        "for i, (train_index, test_index) in tqdm(enumerate(sss.split(X, y)), total=N_RUNS, desc=\"Running simulations\"):\n",
        "\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Create the equivalent fair training and test sets\n",
        "  fair_X_train = fair_heart_disease.loc[fair_heart_disease['ID'].isin(train_index),\n",
        "                                        ['U','age']]\n",
        "  fair_X_test = fair_heart_disease.loc[fair_heart_disease['ID'].isin(test_index),\n",
        "                                       ['U','age']]\n",
        "  fair_y_train = fair_heart_disease.loc[fair_heart_disease['ID'].isin(train_index), 'cvd']\n",
        "  fair_y_test = fair_heart_disease.loc[fair_heart_disease['ID'].isin(test_index), 'cvd']\n",
        "\n",
        "  # Train the baseline and fair models\n",
        "  rf, y_pred, y_pred_proba = train_random_forest(X_train, y_train, X_test, y_test)\n",
        "  fair_rf, fair_y_pred, fair_y_pred_proba = train_random_forest(\n",
        "      fair_X_train, fair_y_train, fair_X_test, fair_y_test)\n",
        "\n",
        "  #GLOBAL PERFORMANCE METRICS\n",
        "  accuracy, roc_auc, FNR, FPR,*_ = get_perf_metrics(y_test, y_pred, y_pred_proba)\n",
        "  fair_accuracy, fair_roc_auc, fair_FNR, fair_FPR,*_ = get_perf_metrics(fair_y_test, fair_y_pred, fair_y_pred_proba)\n",
        "\n",
        "  # COUNTERFACTUAL PREDICTIONS for the baseline model\n",
        "  X_cf_test = X_cf.iloc[test_index]\n",
        "  y_cf_test = y_cf.iloc[test_index]\n",
        "\n",
        "  y_cf_pred = rf.predict(X_cf_test)\n",
        "\n",
        "  # STRATIFIED PERFORMANCE AND FAIRNESS\n",
        "  # Baseline audit dataset\n",
        "  baseline_audit_df = X_test.copy()\n",
        "  baseline_audit_df['y_true'] = y_test\n",
        "  baseline_audit_df['y_pred'] = y_pred\n",
        "  baseline_audit_df['y_pred_proba'] = y_pred_proba\n",
        "  baseline_audit_df['y_cf_pred'] = y_cf_pred\n",
        "\n",
        "  baseline_male_df = baseline_audit_df[baseline_audit_df['sex'] == 1]\n",
        "  baseline_female_df = baseline_audit_df[baseline_audit_df['sex'] == 0]\n",
        "\n",
        "  # Fair audit dataset\n",
        "  fair_audit_df = fair_heart_disease.loc[fair_heart_disease['ID'].isin(test_index),\n",
        "                                       ['U','age','sex']].copy()\n",
        "  fair_audit_df['y_true'] = fair_y_test\n",
        "  fair_audit_df['y_pred'] = fair_y_pred\n",
        "  fair_audit_df['y_pred_proba'] = fair_y_pred_proba\n",
        "  fair_male_df = fair_audit_df[fair_audit_df['sex'] == 1]\n",
        "  fair_female_df = fair_audit_df[fair_audit_df['sex'] == 0]\n",
        "\n",
        "  ### STRATIFIED PERFORMANCE AUDIT\n",
        "  # Baseline Model:\n",
        "  accuracy_m, roc_auc_m, FNR_m, FPR_m, tn_m, fp_m, fn_m, tp_m = get_perf_metrics(\n",
        "      baseline_male_df['y_true'],\n",
        "      baseline_male_df['y_pred'],\n",
        "      baseline_male_df['y_pred_proba'])\n",
        "\n",
        "  accuracy_f, roc_auc_f, FNR_f, FPR_f, tn_f, fp_f, fn_f, tp_f = get_perf_metrics(\n",
        "      baseline_female_df['y_true'],\n",
        "      baseline_female_df['y_pred'],\n",
        "      baseline_female_df['y_pred_proba'])\n",
        "\n",
        "  # Fair Model before correction of direct bias:\n",
        "  fair_accuracy_m, fair_roc_auc_m, fair_FNR_m, fair_FPR_m, *_ = get_perf_metrics(\n",
        "      fair_male_df['y_true'],\n",
        "      fair_male_df['y_pred'],\n",
        "      fair_male_df['y_pred_proba'])\n",
        "\n",
        "  fair_accuracy_f, fair_roc_auc_f, fair_FNR_f, fair_FPR_f, *_ = get_perf_metrics(\n",
        "      fair_female_df['y_true'],\n",
        "      fair_female_df['y_pred'],\n",
        "      fair_female_df['y_pred_proba'])\n",
        "\n",
        "  ### COUNTERFACTUAL FAIRNESS METRICS\n",
        "\n",
        "  #### Baseline Model:\n",
        "\n",
        "  # Frequency of male individuals with a counterfactually flipped prediction\n",
        "  # from y=0 to y=1\n",
        "  flipped_pos_m = (baseline_male_df['y_pred'] == 0) & (baseline_male_df['y_cf_pred'] == 1)\n",
        "  flipped_pos_m_freq = baseline_male_df[flipped_pos_m].shape[0] / baseline_male_df.shape[0]\n",
        "\n",
        "  # Frequency of male individuals with a counterfactually flipped prediction\n",
        "  # from y=1 to y=0\n",
        "  flipped_neg_m = (baseline_male_df['y_pred'] == 1) & (baseline_male_df['y_cf_pred'] == 0)\n",
        "  flipped_neg_m_freq = baseline_male_df[flipped_neg_m].shape[0] / baseline_male_df.shape[0]\n",
        "\n",
        "  # Frequency of male individuals with a counterfactually flipped prediction\n",
        "  # from y=0 to y=1\n",
        "  flipped_pos_f = (baseline_female_df['y_pred'] == 0) & (baseline_female_df['y_cf_pred'] == 1)\n",
        "  flipped_pos_f_freq = baseline_female_df[flipped_pos_f].shape[0] / baseline_female_df.shape[0]\n",
        "\n",
        "  # Frequency of male individuals with a counterfactually flipped prediction\n",
        "  # from y=1 to y=0\n",
        "  flipped_neg_f = (baseline_female_df['y_pred'] == 1) & (baseline_female_df['y_cf_pred'] == 0)\n",
        "  flipped_neg_f_freq = baseline_female_df[flipped_neg_f].shape[0] / baseline_female_df.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  perf_metrics.append({\n",
        "      'run': i,\n",
        "      'accuracy': accuracy,\n",
        "      'roc_auc': roc_auc,\n",
        "      'FNR': FNR,\n",
        "      'FPR': FPR,\n",
        "      'fair_accuracy': fair_accuracy,\n",
        "      'fair_roc_auc': fair_roc_auc,\n",
        "      'fair_FNR': fair_FNR,\n",
        "      'fair_FPR': fair_FPR,\n",
        "      'accuracy_m': accuracy_m,\n",
        "      'accuracy_f': accuracy_f,\n",
        "      'accuracy_diff': accuracy_m - accuracy_f,\n",
        "      'roc_auc_m': roc_auc_m,\n",
        "      'roc_auc_f': roc_auc_f,\n",
        "      'roc_auc_diff': roc_auc_m - roc_auc_f,\n",
        "      'FNR_m': FNR_m,\n",
        "      'FNR_f': FNR_f,\n",
        "      'FNR_diff': FNR_m - FNR_f,\n",
        "      'FPR_m': FPR_m,\n",
        "      'FPR_f': FPR_f,\n",
        "      'FPR_diff': FPR_m - FPR_f,\n",
        "      'fair_accuracy_m': fair_accuracy_m,\n",
        "      'fair_accuracy_f': fair_accuracy_f,\n",
        "      'fair_accuracy_diff': fair_accuracy_m - fair_accuracy_f,\n",
        "      'fair_roc_auc_m': fair_roc_auc_m,\n",
        "      'fair_roc_auc_f': fair_roc_auc_f,\n",
        "      'fair_roc_auc_diff': fair_roc_auc_m - fair_roc_auc_f,\n",
        "      'fair_FNR_m': fair_FNR_m,\n",
        "      'fair_FNR_f': fair_FNR_f,\n",
        "      'fair_FNR_diff': fair_FNR_m - fair_FNR_f,\n",
        "      'fair_FPR_m': fair_FPR_m,\n",
        "      'fair_FPR_f': fair_FPR_f,\n",
        "      'fair_FPR_diff': fair_FPR_m - fair_FPR_f,\n",
        "      'flipped_pos_m': flipped_pos_m_freq,\n",
        "      'flipped_neg_m': flipped_neg_m_freq,\n",
        "      'flipped_pos_f': flipped_pos_f_freq,\n",
        "      'flipped_neg_f': flipped_neg_f_freq\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ZU95kE0P0_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6ZU95kE0P0_",
        "outputId": "3ff59f06-8755-4d73-b1c1-393902081e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance metrics saved\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "save_path = f'{PROJECT_ROOT}/results'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "perf_metrics_df = pd.DataFrame(perf_metrics)\n",
        "date_str = datetime.datetime.now().strftime('%Y-%m-%d_%H%M')\n",
        "perf_metrics_df.to_csv(f'{save_path}/perf_metrics_full_{N_RUNS}_runs_{date_str}.csv')\n",
        "print('Performance metrics saved')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
